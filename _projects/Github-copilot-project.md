---
name: Training Example Reproduction and Vulnerability Assessment on LLM-Generated Code
tools: [Python, CodeQL, CWE, OWASP, GitHub Copilot, REST API, LateX]
image: 
style: fill
color: info
description: A research project to determine if Copilot reproduces training data in its output and inject new vulnerabilities to the code.
---

# Training Example Reproduction and Vulnerability Assessment on LLM-Generated Code
**Currently in Progress - Submitted to University [TUHH]**

GitHub Copilot, an AI-driven code completion tool developed by OpenAI, has revolutionized the way developers write code. However, with great power comes great responsibility. In my recent project, I set out to examine the security and privacy aspects of Copilot, focusing on its vulnerability to specific types of attacks and weaknesses.

## Membership Inference Attack: Testing Privacy
One of my key goals was to perform a membership inference attack on Copilot. This type of attack aims to determine whether a particular piece of data was included in the model's training set. By leveraging Python for my experiments, I simulated scenarios where Copilot generates insecure and vulnerable code from its training dataset or the public repositories. This black box testing approach provided insights into how well Copilot protects the privacy of its training data.

## CodeQL for Vulnerability Assessment
To complement my privacy tests, I conducted a comprehensive vulnerability assessment using CodeQL. CodeQL is a powerful semantic code analysis engine that helps identify potential security issues in codebases. I scanned Copilotâ€™s suggestions for Common Weakness Enumerations (CWEs) as listed by OWASP, such as:

* Injection Flaws: Vulnerabilities that allow an attacker to execute arbitrary code or SQL queries.
* Improper Input Validation: Flaws that occur when user inputs are not correctly validated, leading to potential exploitation.
* Information Disclosure: Weaknesses that may unintentionally reveal sensitive information.

## Findings and Implications
My assessment revealed several critical insights:

**Privacy Risks:** The membership inference attack demonstrated that, under certain conditions, Copilot could inadvertently reproduce code from its training set. This raises concerns about the potential exposure of sensitive information or vulnerability injection.

**Security Vulnerabilities:** Using CodeQL, I identified multiple CWEs in the code suggestions generated by Copilot. These vulnerabilities highlight the need for developers to remain vigilant and manually review AI-generated code to ensure it adheres to security best practices.

<!-- ## Conclusion
As AI-driven tools like GitHub Copilot become integral to software development, it's crucial to continuously evaluate their security and privacy implications. My project underscores the importance of rigorous testing and vulnerability assessments to safeguard against potential risks. By understanding and addressing these vulnerabilities, we can better protect sensitive information and enhance the overall security of AI-powered development tools. -->

## What I learned:
Through this project, I learned how to work independently, effectively managing my responsibilities as a working student while balancing university studies along with being dedicated to the project. This experience taught me to be analytical, accountable and reliable, ensuring that I could meet all deadlines and deliver high-quality work despite the demands of multiple commitments.

<p class="text-center">
<!-- {% include elements/button.html link="https://github.com/tiramdasg/bored-coyote.git" text="See the Project" %} -->
The project will be available online after the approval at the university.
</p>